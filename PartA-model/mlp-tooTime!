import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU
from tensorflow.keras.optimizers import Adam, SGD, AdamW
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint
from tensorflow.keras.regularizers import l1, l2, l1_l2
from tensorflow.keras.metrics import Precision, Recall
import matplotlib.pyplot as plt
import seaborn as sns
import time

# Step 1: Data Loading and Preprocessing
def load_and_preprocess_data(file_path):
    data = pd.read_csv(file_path)
    X = data.iloc[:, :-1].values / 255.0  # Normalize features
    y = data.iloc[:, -1].values
    
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    y_categorical = to_categorical(y_encoded)
    
    # Compute class weights
    class_weights = compute_class_weight('balanced', classes=np.unique(y_encoded), y=y_encoded)
    class_weight_dict = dict(enumerate(class_weights))
    
    return X, y_categorical, class_weight_dict, label_encoder

# Step 2: Model Creation
def create_model(num_layers, neurons_per_layer, activation='relu', optimizer='adam', regularizer='l2', dropout_rate=0.3, learning_rate=0.001):
    model = Sequential()
    
    for i in range(num_layers):
        if i == 0:
            model.add(Dense(neurons_per_layer[i], activation=activation, input_shape=(9,), 
                            kernel_regularizer=l1(0.01) if regularizer == 'l1' else (l2(0.01) if regularizer == 'l2' else l1_l2(l1=0.01, l2=0.01))))
        else:
            model.add(Dense(neurons_per_layer[i], activation=activation, 
                            kernel_regularizer=l1(0.01) if regularizer == 'l1' else (l2(0.01) if regularizer == 'l2' else l1_l2(l1=0.01, l2=0.01))))
        model.add(BatchNormalization())
        model.add(Dropout(dropout_rate))
    
    model.add(Dense(182, activation='softmax'))
    
    if optimizer == 'adam':
        opt = Adam(learning_rate=learning_rate)
    elif optimizer == 'sgd':
        opt = SGD(learning_rate=learning_rate)
    elif optimizer == 'adamw':
        opt = AdamW(learning_rate=learning_rate)
    
    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])
    return model

# Step 3: Hyperparameter Search
# Modify the random_search_cv function
def random_search_cv(param_grid, X, y, class_weight_dict, n_iter=50, n_splits=5):
    best_score = 0
    best_params = {}
    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    start_time = time.time()
    
    for i in range(n_iter):
        params = {}
        for k, v in param_grid.items():
            if k == 'neurons_per_layer':
                params[k] = v[np.random.choice(len(v))]
            else:
                params[k] = np.random.choice(v)
        
        if len(params['neurons_per_layer']) != params['num_layers']:
            continue
        
        scores = []
        for train_index, val_index in cv.split(X, np.argmax(y, axis=1)):
            X_train, X_val = X[train_index], X[val_index]
            y_train, y_val = y[train_index], y[val_index]
            
            model = create_model(**params)
            
            # Callbacks
            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)
            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
            
            history = model.fit(
                X_train, y_train,
                epochs=100,
                batch_size=32,
                validation_data=(X_val, y_val),
                callbacks=[reduce_lr, early_stopping],
                class_weight=class_weight_dict,
                verbose=0
            )
            
            # Evaluate
            val_pred = model.predict(X_val)
            val_pred_classes = np.argmax(val_pred, axis=1)
            val_true_classes = np.argmax(y_val, axis=1)
            score = f1_score(val_true_classes, val_pred_classes, average='weighted')
            scores.append(score)
        
        avg_score = np.mean(scores)
        print(f"Iteration {i+1}/{n_iter}, Score: {avg_score:.4f}")
        
        if avg_score > best_score:
            best_score = avg_score
            best_params = params
            print("New best configuration found!")
    
    end_time = time.time()
    print(f"\nHyperparameter search time: {end_time - start_time:.2f} seconds")
    
    return best_params, best_score


# Step 4: Final Model Training and Evaluation
def train_and_evaluate_final_model(X, y, best_params, class_weight_dict, n_splits=5):
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    fold_scores = []
    all_y_true = []
    all_y_pred = []
    
    start_time = time.time()
    
    for fold, (train_index, val_index) in enumerate(skf.split(X, np.argmax(y, axis=1)), 1):
        X_train, X_val = X[train_index], X[val_index]
        y_train, y_val = y[train_index], y[val_index]
        
        model = create_model(**best_params)
        
        # Callbacks
        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)
        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
        model_checkpoint = ModelCheckpoint(f'best_model_fold_{fold}.h5', save_best_only=True, monitor='val_loss')
        
        history = model.fit(
            X_train, y_train,
            epochs=200,
            batch_size=32,
            validation_data=(X_val, y_val),
            callbacks=[reduce_lr, early_stopping, model_checkpoint],
            class_weight=class_weight_dict,
            verbose=0
        )
        
        # Evaluate
        val_pred = model.predict(X_val)
        val_pred_classes = np.argmax(val_pred, axis=1)
        val_true_classes = np.argmax(y_val, axis=1)
        score = f1_score(val_true_classes, val_pred_classes, average='weighted')
        fold_scores.append(score)
        
        all_y_true.extend(val_true_classes)
        all_y_pred.extend(val_pred_classes)
        
        print(f"Fold {fold}")
        print(f"Accuracy: {accuracy_score(val_true_classes, val_pred_classes):.4f}")
        print(f"F1-Score: {score:.4f}")
        
        # Plot learning curves
        plt.figure(figsize=(12, 4))
        plt.subplot(1, 2, 1)
        plt.plot(history.history['loss'], label='Training Loss')
        plt.plot(history.history['val_loss'], label='Validation Loss')
        plt.title(f'Model Loss - Fold {fold}')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.subplot(1, 2, 2)
        plt.plot(history.history['accuracy'], label='Training Accuracy')
        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
        plt.title(f'Model Accuracy - Fold {fold}')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        plt.tight_layout()
        plt.show()
    
    end_time = time.time()
    
    print("\nAdvanced Keras MLP Results:")
    print(f"Mean Accuracy: {np.mean(fold_scores):.4f} (+/- {np.std(fold_scores):.4f})")
    print(f"Mean F1-Score: {np.mean(fold_scores):.4f}")
    
    # Calculate overall precision and recall
    precision = precision_score(all_y_true, all_y_pred, average='weighted')
    recall = recall_score(all_y_true, all_y_pred, average='weighted')
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    
    print(f"Training time: {end_time - start_time:.2f} seconds")
    
    return np.mean(fold_scores), all_y_true, all_y_pred

# Main execution
if __name__ == "__main__":
    # Load and preprocess data
    X, y, class_weight_dict, label_encoder = load_and_preprocess_data('final_dataset.csv')
    
    # Split data into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=np.argmax(y, axis=1), random_state=42)
    
    # Define hyperparameter grid
    param_grid = {
        'num_layers': [2, 3, 4],
        'neurons_per_layer': [(256, 128), (256, 128, 64), (512, 256, 128, 64)],
        'activation': ['relu', 'tanh', 'leaky_relu'],
        'optimizer': ['adam', 'adamw'],
        'regularizer': ['l2', 'l1_l2'],
        'dropout_rate': [0.3, 0.4, 0.5],
        'learning_rate': [0.001, 0.0001]
    }
    
    # Perform hyperparameter search
    best_params, best_score = random_search_cv(param_grid, X_train, y_train, class_weight_dict)
    print("Best hyperparameters:", best_params)
    print("Best score:", best_score)
    
    # Train and evaluate final model
    final_score, all_y_true, all_y_pred = train_and_evaluate_final_model(X_train, y_train, best_params, class_weight_dict)
    
    # Generate classification report
    class_names = label_encoder.classes_
    print("\nClassification Report:")
    print(classification_report(all_y_true, all_y_pred, target_names=class_names))
    
    # Generate confusion matrix
    plt.figure(figsize=(20, 16))
    cm = confusion_matrix(all_y_true, all_y_pred)
    sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.title('Confusion Matrix (Advanced Keras MLP)')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.tight_layout()
    plt.show()
    
    # Evaluate on test set
    final_model = create_model(**best_params)
    final_model.fit(X_train, y_train, epochs=200, batch_size=32, class_weight=class_weight_dict, verbose=0)
    y_pred = final_model.predict(X_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true_classes = np.argmax(y_test, axis=1)
    
    print("\nTest Set Evaluation:")
    print(f"Test Accuracy: {accuracy_score(y_true_classes, y_pred_classes):.4f}")
    print(f"Test F1-score: {f1_score(y_true_classes, y_pred_classes, average='weighted'):.4f}")
    print(f"Test Precision: {precision_score(y_true_classes, y_pred_classes, average='weighted'):.4f}")
    print(f"Test Recall: {recall_score(y_true_classes, y_pred_classes, average='weighted'):.4f}")
    
# Modify the model complexity calculation
def count_parameters(model):
    return model.count_params()

total_params = count_parameters(final_model)
print(f"\nTotal number of parameters: {total_params}")