{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Emotion Detector\n",
    "\n",
    "##### In this notebook, we will focus on building and training a Convolutional Neural Network (CNN) model to analyze facial expressions in images. \n",
    "##### The CNN is a type of deep learning model that is particularly good at processing images. \n",
    "##### We will train our CNN to recognize different emotions based on facial expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from mtcnn import MTCNN\n",
    "from keras.models import load_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "We load the FER2013 dataset and preprocess it. This involves converting the pixel values from strings to integers, reshaping the data into the original image shape, and normalizing the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('fer2013.csv')\n",
    "\n",
    "# Convert pixels to a numpy array\n",
    "data['pixels'] = data['pixels'].apply(lambda pixel_sequence: np.fromstring(pixel_sequence, sep=' '))\n",
    "\n",
    "# Reshape and normalize the data\n",
    "X = np.vstack(data['pixels'].values)\n",
    "X = X.reshape(-1, 48, 48, 1)\n",
    "X = X.astype('float32')\n",
    "X /= 255.0\n",
    "\n",
    "# Convert labels to a numpy array\n",
    "y = data['emotion'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data \n",
    "We split the data into a training set and a test set. This allows us to evaluate the performance of our model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Train the model \n",
    "We define our CNN model for facial expression recognition and train it on our preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "\n",
    "# Add a pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add another pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the tensor output from the previous layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected layer\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(units=7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model \n",
    "After training, we save our model so that we can use it later without having to retrain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('expression_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model and use it for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the face detection model\n",
    "detector = MTCNN()\n",
    "\n",
    "# Load the facial expression recognition model\n",
    "expression_model = load_model('expression_model.h5')\n",
    "\n",
    "# Load the painting\n",
    "img = cv2.imread('your_painting.jpg')\n",
    "\n",
    "# Detect faces in the painting\n",
    "results = detector.detect_faces(img)\n",
    "\n",
    "for result in results:\n",
    "    # Get the bounding box coordinates\n",
    "    x1, y1, width, height = result['box']\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "\n",
    "    # Crop the face from the painting\n",
    "    face = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Preprocess the face\n",
    "    face = cv2.resize(face, (48, 48))\n",
    "    face = face.astype('float32') / 255\n",
    "    face = np.expand_dims(face, axis=0)\n",
    "\n",
    "    # Predict the facial expression\n",
    "    prediction = expression_model.predict(face)\n",
    "    emotion = np.argmax(prediction[0])\n",
    "\n",
    "    # Print the predicted emotion\n",
    "    print(emotion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
